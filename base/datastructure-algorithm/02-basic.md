# 一、数组

低效的“插入”和“删除”

很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。

如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法 搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个 存储数据的集合。在这种情况下，如果要将某个数组插入到第 k 个位置，为了避免大规模 的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最 后，把新的元素直接放入第 k 个位置。

实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次 删除操作集中在一起执行，删除的效率是不是会提高很多呢？

为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。 每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存 储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬 移。如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？

容器能否完全替代数组？ 针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？

如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好 了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以， 如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。

1. Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基 本类型，就可以选用数组。 

2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方 法，也可以直接使用数组。 
3. 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList array。 我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完 全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性 能的优化需要做到极致，这个时候数组就会优于容器，成为首选。

从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也 讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就 表示偏移 k 个 type_size 的位置

JVM标记清除算法： 大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作 才会开始。

# 二、链表

最常见的链表结构，它们分别是：单链表、双 向链表和循环链表。

几个写链表代码技巧

技巧一：理解指针或引用的含义 

事实上，看懂链表的结构并不是很难，但是一旦把它和指针混在一起，就很容易让人摸不着 头脑。所以，要想写对链表代码，首先就要理解好指针。 我们知道，有些语言有“指针”的概念，比如 C 语言；有些语言没有指针，取而代之的 是“引用”，比如 Java、Python。不管是“指针”还是“引用”，实际上，它们的意思都 是一样的，都是存储所指对象的内存地址。

拿 C 语言中的“指针”来讲解，如果你用的是 Java 或者其他没有指针的语言 也没关系，你把它理解成“引用”就可以了。

将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中 存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。

技巧二：警惕指针丢失和内存泄漏

技巧三：利用哨兵简化实现难度

技巧四：重点留意边界条件处理

常用来检查链表代码是否正确的边界条件有这样几个：

如果链表为空时，代码是否能正常工作？ 

如果链表只包含一个结点时，代码是否能正常工作？ 

如果链表只包含两个结点时，代码是否能正常工作？ 

代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

5 个常见的链表操作。你只要把这几个操作都能写熟练，不熟就多写几 遍，我保证你之后再也不会害怕写链表代码。

**单链表反转 链表中环的检测 两个有序的链表合并 删除链表倒数第 n 个结点 求链表的中间结点**

# 三、栈

栈在函数调用中的应用

操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种 结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入 栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。

栈在表达式求值中的应用

栈在括号匹配中的应用

# 四、队列

队列的应用 也非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。 它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。

循环队列

阻塞队列和并发队列，“生产者 - 消费者模型”

线程安全的队列我们叫作并发队列。最简单直接的实现方式是直接在 enqueue()、 dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操 作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。 这也是循环队列比链式队列应用更加广泛的原因。除了前面讲到队列应用在线程池请求排队的场景之外，队列可以应用在任何有限资源池中， 用于排队请求，比如数据库连接池等。对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

# 五、递归

**递归需要满足的三个条件**

1. 一个问题的解可以分解为几个子问题的解
2.  这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
3. 存在递归终止条件

**编写递归代码**

写出递推公式，找到终止条件

写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写 出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。

对于递归代码，这种试图想清楚整个递和归过程的做法，实际上是进入了一个思维误区。很 多时候，我们理解起来比较吃力，主要原因就是自己给自己制造了这种理解障碍。那正确的 思维方式应该是怎样的呢？

如果一个问题 A 可以分解为若干子问题 B、C、D，你可以假设子问题 B、C、D 已经解 决，在此基础上思考如何解决问题 A。而且，你只需要思考问题 A 与子问题 B、C、D 两层 之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间 的关系。屏蔽掉递归细节，这样子理解起来就简单多了。

编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一 层层的调用关系，不要试图用人脑去分解递归的每个步骤。

**递归代码要警惕堆栈溢出**

函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时 变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一 般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的 风险。

**递归代码要警惕重复计算**

为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经求解过的 f(k)。 当递归调用到 f(k) 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回， 不需要重复计算，这样就能避免刚讲的问题了。

**将递归代码改写为非递归代码**

那是不是所有的递归代码都可以改为这种迭代循环的非递归写法呢？ 笼统地讲，是的。因为递归本身就是借助栈来实现的，只不过我们使用的栈是系统或者虚拟 机本身提供的，我们没有感知罢了。如果我们自己在内存堆上实现栈，手动模拟入栈、出栈 过程，这样任何递归代码都可以改写成看上去不是递归代码的样子。 但是这种思路实际上是将递归改为了“手动”递归，本质并没有变，而且也并没有解决前面 讲到的某些问题，徒增了实现的复杂度。

调试递归: 1.打印日志发现，递归值。 2.结合条件断点进行调试。

# 六、排序

插入 排序和冒泡排序的时间复杂度相同，都是 O(n )，在实际的软件开发里，为什么我们更倾 向于使用插入排序算法而不是冒泡排序算法呢？

**冒泡排序**

**插入排序**

已排序区间和未排序区间。初始已排序区间只有 一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程， 直到未排序区间中元素为空，算法结束。

**选择排序**

冒泡排序不管怎么优化，元素交换的次数是 一个固定值，是原始数据的逆序度。插入排序是同样的，不管怎么优化，元素移动的次数也 等于原始数据的逆序度。冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序 需要 3 个赋值操作，而插入排序只需要 1 个。

**归并排序和快速排序**。这两种排序算法适合大规模的数据排序，归并排序和快速排序都用到了分治思想

**归并排序**

归并排序的核心思想还是蛮简单的。如果要排序一个数组，我们先把数组从中间分成前后两 部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有 序了。分治是一种解决问题的处理思想，递归是一种编程技巧。

归并排序的执行效率与要排序的原始数组的有序程度 无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间 复杂度都是 O(nlogn)。

归并排序不是原地排序算法。归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。

归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相 反，它的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的、时 间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。

七、线性排序

八、排序优化

九、二分查找

十、跳表

